# worlds-fastest-roller-coasters-
Looking at the top fastest roller coasters from around the world. 

In this project, I aimed to understand, prepare, and analyze the roller coaster dataset using Python and pandas notebooks. The main objectives were as follows:

Understanding the Data: Initially, I explored the dataset to gain insights into its structure, the number of rows, columns, and the types of data present. This step was crucial in understanding the scope of the project and the possible analyses to be conducted.

Preparing the Data: Data preparation is vital to ensure the dataset is clean and suitable for analysis. I addressed any missing values, removed irrelevant columns, and applied data transformations where necessary.

Univariate Analysis: To better understand individual variables, I conducted univariate analysis. I examined the distribution, central tendency, and variability of key features like speed, height, inversions, and g-force. This step provided valuable insights into the characteristics of roller coasters.

Exploring Relationships: I delved into the relationships between different variables in the dataset. Using visualization libraries such as Matplotlib and Seaborn, I identified correlations and patterns between speed, height, and other ride attributes.

Answering the Key Question: One of the primary objectives of the project was to answer the question, "What are the locations with the fastest roller coasters (with a minimum of 10 roller coasters at that location)?" I used Python's data manipulation and filtering capabilities to arrive at a meaningful answer to this question.

Learning Experience:
This project has been an incredible learning experience for me. Working with Python, pandas, Matplotlib, and Seaborn allowed me to gain hands-on experience in data manipulation, analysis, and visualization. I discovered various features and capabilities of these libraries, enabling me to perform data-driven analyses with confidence.

Throughout the project, I honed my skills in data cleaning, handling missing data, and extracting meaningful insights from a vast dataset. I also became proficient in using Matplotlib and Seaborn to create captivating visualizations, making the analysis process more engaging and effective.

Overall, this project has been a pivotal learning journey, equipping me with valuable skills in Python and data analysis, and fueling my passion for exploring and understanding real-world datasets.
